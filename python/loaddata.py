"""
Snowflake Incremental Monthly Upload Script
Dataset: Sales/Invoice Data
Credentials loaded from environment variables (GitHub Secrets)
"""

import os
import pandas as pd
import snowflake.connector
from snowflake.connector.pandas_tools import write_pandas
import logging
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()  # Load environment variables from .env file (if exists)
# â”€â”€ Logging Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_FILE = f"D:\\snowflake-incremental-pipeline\\logs\\snowflake_upload_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

os.makedirs("logs", exist_ok=True)

file_handler = logging.FileHandler(LOG_FILE, encoding="utf-8")
console_handler = logging.StreamHandler()

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[file_handler, console_handler]
)

log = logging.getLogger(__name__)


# â”€â”€ Snowflake Config â€” reads from environment variables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SNOWFLAKE_CONFIG = {
    "user":      os.getenv("SNOWFLAKE_USER"),
    "password":  os.getenv("SNOWFLAKE_PASSWORD"),
    "account":   os.getenv("SNOWFLAKE_ACCOUNT"),
    "warehouse": os.getenv("SNOWFLAKE_WAREHOUSE"),
    "database":  os.getenv("SNOWFLAKE_DATABASE"),
    "schema":    os.getenv("SNOWFLAKE_SCHEMA")
}


TABLE_NAME  = "RAW_SALES"
CSV_FILE    = r"d:\snowflake-incremental-pipeline\python\online_sales_dataset.csv"
DATE_COLUMN = "InvoiceDate"


# â”€â”€ Step 1: Connect to Snowflake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_connection():
    log.info("Connecting to Snowflake...")
    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)
    log.info("âœ… Connected successfully!")
    return conn


# â”€â”€ Step 2: Create Table If Not Exists â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_table_if_not_exists(conn):
    cursor = conn.cursor()
    cursor.execute(f"""
        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
            InvoiceNo          VARCHAR,
            StockCode          VARCHAR,
            Description        VARCHAR,
            Quantity           NUMBER,
            InvoiceDate        VARCHAR,
            UnitPrice          FLOAT,
            CustomerID         FLOAT,
            Country            VARCHAR,
            Discount           FLOAT,
            PaymentMethod      VARCHAR,
            ShippingCost       FLOAT,
            Category           VARCHAR,
            SalesChannel       VARCHAR,
            ReturnStatus       VARCHAR,
            ShipmentProvider   VARCHAR,
            WarehouseLocation  VARCHAR,
            OrderPriority      VARCHAR
        )
    """)
    log.info(f"âœ… Table '{TABLE_NAME}' ready.")
    cursor.close()


# â”€â”€ Step 3: Get Already Loaded Months from Snowflake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_existing_months(conn):
    cursor = conn.cursor()
    try:
        cursor.execute(f"""
            SELECT DISTINCT
                YEAR(TO_TIMESTAMP(InvoiceDate, 'YYYY-MM-DD HH24:MI:SS'))  AS yr,
                MONTH(TO_TIMESTAMP(InvoiceDate, 'YYYY-MM-DD HH24:MI:SS')) AS mn
            FROM {TABLE_NAME}
        """)
        results = cursor.fetchall()
        existing = set(results)
        log.info(f"ğŸ“¦ Months already in Snowflake: {existing if existing else 'None (empty table)'}")
        return existing
    except Exception as e:
        log.warning(f"Could not fetch existing months (table may be empty): {e}")
        return set()
    finally:
        cursor.close()


# â”€â”€ Step 4: Load Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_dataset(filepath):
    log.info(f"ğŸ“‚ Loading dataset from: {filepath}")
    df = pd.read_csv(filepath)

    # Parse date column â€” format: 2020-01-01 00:00
    df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], format="%Y-%m-%d %H:%M")

    # Add helper columns for grouping BEFORE converting to string
    df["_year"]  = df[DATE_COLUMN].dt.year
    df["_month"] = df[DATE_COLUMN].dt.month

    # Convert to string format Snowflake accepts: YYYY-MM-DD HH:MM:SS
    df[DATE_COLUMN] = df[DATE_COLUMN].dt.strftime("%Y-%m-%d %H:%M:%S")

    # Uppercase column names for Snowflake compatibility
    df.columns = [c.upper() if not c.startswith("_") else c for c in df.columns]

    log.info(f"âœ… Dataset loaded: {len(df)} rows | Date range: {df['INVOICEDATE'].min()} â†’ {df['INVOICEDATE'].max()}")
    return df


# â”€â”€ Step 5: Upload Only One New Month then Stop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upload_new_months(conn, df):
    existing_months = get_existing_months(conn)

    month_groups   = df.groupby(["_year", "_month"])
    uploaded_count = 0
    skipped_count  = 0

    for (yr, mn), group_df in month_groups:
        yr, mn = int(yr), int(mn)
        month_label = f"{yr}-{mn:02d} ({datetime(yr, mn, 1).strftime('%B %Y')})"

        if (yr, mn) in existing_months:
            log.info(f"â­ï¸  SKIP   | {month_label} â€” already loaded ({len(group_df)} rows)")
            skipped_count += 1
            continue

        upload_df = group_df.drop(columns=["_year", "_month"]).reset_index(drop=True)
        log.info(f"â¬†ï¸  UPLOAD | {month_label} â€” {len(upload_df)} rows uploading...")

        try:
            success, _, num_rows, _ = write_pandas(conn, upload_df, TABLE_NAME, auto_create_table=False)
            if success:
                log.info(f"âœ…  DONE   | {month_label} â€” {num_rows} rows uploaded successfully!")
                log.info(f"ğŸ›‘ STOPPED | One month per run. Next month uploads tomorrow.")
                uploaded_count += 1
            else:
                log.error(f"âŒ  FAILED | {month_label} â€” write_pandas returned failure")
        except Exception as e:
            log.error(f"âŒ  ERROR  | {month_label} â€” {str(e)}")

        break  # Stop after first new month

    log.info("=" * 60)
    log.info(f"ğŸ“Š UPLOAD SUMMARY")
    log.info(f"   âœ… Uploaded : {uploaded_count} month(s)")
    log.info(f"   â­ï¸  Skipped  : {skipped_count} month(s) (already existed)")
    log.info("=" * 60)

    if uploaded_count == 0:
        log.info("ğŸ‰ Snowflake is already up to date â€” nothing new to upload!")


# â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    log.info("=" * 60)
    log.info("ğŸš€ Starting Snowflake Monthly Incremental Upload")
    log.info("=" * 60)

    conn = get_connection()
    try:
        create_table_if_not_exists(conn)
        df = load_dataset(CSV_FILE)
        upload_new_months(conn, df)
    finally:
        conn.close()
        log.info("ğŸ”’ Snowflake connection closed.")


if __name__ == "__main__":
    main()